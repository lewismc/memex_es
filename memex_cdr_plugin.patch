Index: build.xml
===================================================================
--- build.xml	(revision 1693468)
+++ build.xml	(working copy)
@@ -172,6 +172,7 @@
       <packageset dir="${plugins.dir}/feed/src/java"/>
       <packageset dir="${plugins.dir}/headings/src/java"/>
       <packageset dir="${plugins.dir}/index-anchor/src/java"/>
+      <packageset dir="${plugins.dir}/index-memex-atf/src/java"/>
       <packageset dir="${plugins.dir}/index-basic/src/java"/>
       <packageset dir="${plugins.dir}/index-metadata/src/java"/>
       <packageset dir="${plugins.dir}/index-more/src/java"/>
@@ -181,6 +182,7 @@
       <packageset dir="${plugins.dir}/mimetype-filter/src/java"/>
       <packageset dir="${plugins.dir}/indexer-dummy/src/java"/>
       <packageset dir="${plugins.dir}/indexer-elastic/src/java/" />
+      <packageset dir="${plugins.dir}/indexer-memex/src/java/" />
       <packageset dir="${plugins.dir}/indexer-solr/src/java"/>
       <packageset dir="${plugins.dir}/language-identifier/src/java"/>
       <packageset dir="${plugins.dir}/lib-http/src/java"/>
@@ -585,6 +587,7 @@
       <packageset dir="${plugins.dir}/feed/src/java"/>
       <packageset dir="${plugins.dir}/headings/src/java"/>
       <packageset dir="${plugins.dir}/index-anchor/src/java"/>
+      <packageset dir="${plugins.dir}/index-memex-atf/src/java"/>
       <packageset dir="${plugins.dir}/index-basic/src/java"/>
       <packageset dir="${plugins.dir}/index-geoip/src/java"/>
       <packageset dir="${plugins.dir}/index-metadata/src/java"/>
@@ -594,6 +597,7 @@
       <packageset dir="${plugins.dir}/mimetype-filter/src/java"/>
       <packageset dir="${plugins.dir}/indexer-dummy/src/java"/>
       <packageset dir="${plugins.dir}/indexer-elastic/src/java/" />
+      <packageset dir="${plugins.dir}/indexer-memex/src/java/" />
       <packageset dir="${plugins.dir}/indexer-solr/src/java"/>
       <packageset dir="${plugins.dir}/language-identifier/src/java"/>
       <packageset dir="${plugins.dir}/lib-http/src/java"/>
@@ -978,6 +982,8 @@
         <source path="${plugins.dir}/headings/src/java/" />
         <source path="${plugins.dir}/index-anchor/src/java/" />
         <source path="${plugins.dir}/index-anchor/src/test/" />
+        <source path="${plugins.dir}/index-memex-atf/src/java"/>
+        <source path="${plugins.dir}/index-memex-atf/src/test"/>
         <source path="${plugins.dir}/index-basic/src/java/" />
         <source path="${plugins.dir}/index-basic/src/test/" />
         <source path="${plugins.dir}/index-geoip/src/java/" />
@@ -987,6 +993,7 @@
         <source path="${plugins.dir}/indexer-dummy/src/java/" />
         <source path="${plugins.dir}/indexer-solr/src/java/" />
         <source path="${plugins.dir}/indexer-elastic/src/java/" />
+        <source path="${plugins.dir}/indexer-memex/src/java/" />
         <source path="${plugins.dir}/index-metadata/src/java/" />
         <source path="${plugins.dir}/index-more/src/java/" />
         <source path="${plugins.dir}/index-more/src/test/" />
Index: ivy/ivy.xml
===================================================================
--- ivy/ivy.xml	(revision 1693468)
+++ ivy/ivy.xml	(working copy)
@@ -34,6 +34,9 @@
 	</publications>
 	
 	<dependencies>
+		
+		<dependency org="com.googlecode.json-simple" name="json-simple" rev="1.1.1" />
+		
 		<dependency org="org.slf4j" name="slf4j-api" rev="1.6.1"
 			conf="*->master" />
 		<dependency org="org.slf4j" name="slf4j-log4j12" rev="1.6.1"
Index: ivy/ivysettings.xml
===================================================================
--- ivy/ivysettings.xml	(revision 1693468)
+++ ivy/ivysettings.xml	(working copy)
@@ -28,6 +28,9 @@
   <property name="oss.sonatype.org" 
     value="http://oss.sonatype.org/content/repositories/releases/" 
     override="false"/>
+  <property name="sonatype" 
+    value="https://oss.sonatype.org/content/groups/public/" 
+    override="false"/>
   <property name="repo.maven.org"
     value="http://repo1.maven.org/maven2/"
     override="false"/>
@@ -54,16 +57,22 @@
       changingPattern=".*SNAPSHOT.*" 
       checkmodified="true"
       />
-    <ibiblio name="sonatype"
+    <ibiblio name="sonatype-releases"
       root="${oss.sonatype.org}"
       pattern="${maven2.pattern.ext}"
       m2compatible="true"
       />
+    <ibiblio name="sonatype-groups"
+      root="${sonatype}"
+      pattern="${maven2.pattern.ext}"
+      m2compatible="true"
+    />
     <chain name="default" dual="true">
       <resolver ref="local"/>
       <resolver ref="maven2"/>
       <resolver ref="apache-snapshot"/>
-      <resolver ref="sonatype"/>
+      <resolver ref="sonatype-releases"/>
+      <resolver ref="sonatype-groups"/>
     </chain>
     <chain name="internal">
       <resolver ref="local"/>
@@ -74,7 +83,8 @@
     <chain name="external-and-snapshots">
       <resolver ref="maven2"/>
       <resolver ref="apache-snapshot"/>
-      <resolver ref="sonatype"/>
+      <resolver ref="sonatype-releases"/>
+      <resolver ref="sonatype-groups"/>
     </chain>
   </resolvers>
   <modules>
Index: src/bin/nutch
===================================================================
--- src/bin/nutch	(revision 1693468)
+++ src/bin/nutch	(working copy)
@@ -128,11 +128,12 @@
 
 JAVA="$JAVA_HOME/bin/java"
 JAVA_HEAP_MAX=-Xmx1000m 
+NUTCH_HEAPSIZE=6000
 
 # check envvars which might override default args
 if [ "$NUTCH_HEAPSIZE" != "" ]; then
   #echo "run with heapsize $NUTCH_HEAPSIZE"
-  JAVA_HEAP_MAX="-Xmx""$NUTCH_HEAPSIZE""m"
+  JAVA_HEAP_MAX="-Xmx""$NUTCH_HEAPSIZE"
   #echo $JAVA_HEAP_MAX
 fi
 
Index: src/java/org/apache/nutch/indexer/IndexerMapReduce.java
===================================================================
--- src/java/org/apache/nutch/indexer/IndexerMapReduce.java	(revision 1693468)
+++ src/java/org/apache/nutch/indexer/IndexerMapReduce.java	(working copy)
@@ -22,6 +22,8 @@
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+import org.apache.commons.codec.binary.Base64;
+import org.apache.commons.codec.binary.StringUtils;
 import org.apache.hadoop.conf.Configured;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
@@ -48,12 +50,13 @@
 import org.apache.nutch.parse.ParseData;
 import org.apache.nutch.parse.ParseImpl;
 import org.apache.nutch.parse.ParseText;
+import org.apache.nutch.protocol.Content;
 import org.apache.nutch.scoring.ScoringFilterException;
 import org.apache.nutch.scoring.ScoringFilters;
 
 public class IndexerMapReduce extends Configured implements
-    Mapper<Text, Writable, Text, NutchWritable>,
-    Reducer<Text, NutchWritable, Text, NutchIndexAction> {
+Mapper<Text, Writable, Text, NutchWritable>,
+Reducer<Text, NutchWritable, Text, NutchIndexAction> {
 
   public static final Logger LOG = LoggerFactory
       .getLogger(IndexerMapReduce.class);
@@ -64,10 +67,12 @@
   public static final String INDEXER_SKIP_NOTMODIFIED = "indexer.skip.notmodified";
   public static final String URL_FILTERING = "indexer.url.filters";
   public static final String URL_NORMALIZING = "indexer.url.normalizers";
+  public static final String INDEXER_BINARY_AS_BASE64 = "indexer.binary.base64";
 
   private boolean skip = false;
   private boolean delete = false;
   private boolean deleteRobotsNoIndex = false;
+  private boolean base64 = false;
   private IndexingFilters filters;
   private ScoringFilters scfilters;
 
@@ -91,6 +96,7 @@
     this.deleteRobotsNoIndex = job.getBoolean(INDEXER_DELETE_ROBOTS_NOINDEX,
         false);
     this.skip = job.getBoolean(INDEXER_SKIP_NOTMODIFIED, false);
+    this.base64 = job.getBoolean(INDEXER_BINARY_AS_BASE64, false);
 
     normalize = job.getBoolean(URL_NORMALIZING, false);
     filter = job.getBoolean(URL_FILTERING, false);
@@ -159,7 +165,7 @@
 
   public void map(Text key, Writable value,
       OutputCollector<Text, NutchWritable> output, Reporter reporter)
-      throws IOException {
+          throws IOException {
 
     String urlString = filterUrl(normalizeUrl(key.toString()));
     if (urlString == null) {
@@ -173,10 +179,11 @@
 
   public void reduce(Text key, Iterator<NutchWritable> values,
       OutputCollector<Text, NutchIndexAction> output, Reporter reporter)
-      throws IOException {
+          throws IOException {
     Inlinks inlinks = null;
     CrawlDatum dbDatum = null;
     CrawlDatum fetchDatum = null;
+    Content content = null;
     ParseData parseData = null;
     ParseText parseText = null;
 
@@ -219,6 +226,8 @@
         }
       } else if (value instanceof ParseText) {
         parseText = (ParseText) value;
+      } else if (value instanceof Content) {
+        content = (Content)value;
       } else if (LOG.isWarnEnabled()) {
         LOG.warn("Unrecognized type: " + value.getClass());
       }
@@ -267,15 +276,15 @@
     }
 
     NutchDocument doc = new NutchDocument();
-    doc.add("id", key.toString());
+    //doc.add("id", key.toString());
 
     final Metadata metadata = parseData.getContentMeta();
 
     // add segment, used to map from merged index back to segment files
-    doc.add("segment", metadata.get(Nutch.SEGMENT_NAME_KEY));
+    //doc.add("segment", metadata.get(Nutch.SEGMENT_NAME_KEY));
 
     // add digest, used by dedup
-    doc.add("digest", metadata.get(Nutch.SIGNATURE_KEY));
+    //doc.add("digest", metadata.get(Nutch.SIGNATURE_KEY));
 
     final Parse parse = new ParseImpl(parseText, parseData);
     try {
@@ -325,8 +334,21 @@
     // apply boost to all indexed fields.
     doc.setWeight(boost);
     // store boost for use by explain and dedup
-    doc.add("boost", Float.toString(boost));
+    //doc.add("boost", Float.toString(boost));
 
+    if (content != null) {
+      // Get the original unencoded content
+      String binary = new String(content.getContent());
+
+      // optionally encode as base64
+      if (base64) {
+        binary = Base64.encodeBase64String(StringUtils.getBytesUtf8(binary));
+      }
+
+      //doc.add("binaryContent", binary);
+      doc.add("raw_content", binary);
+    }
+
     reporter.incrCounter("IndexerStatus", "indexed (add/update)", 1);
 
     NutchIndexAction action = new NutchIndexAction(doc, NutchIndexAction.ADD);
@@ -337,7 +359,7 @@
   }
 
   public static void initMRJob(Path crawlDb, Path linkDb,
-      Collection<Path> segments, JobConf job) {
+      Collection<Path> segments, JobConf job, boolean addBinaryContent) {
 
     LOG.info("IndexerMapReduce: crawldb: " + crawlDb);
 
@@ -352,6 +374,10 @@
           CrawlDatum.PARSE_DIR_NAME));
       FileInputFormat.addInputPath(job, new Path(segment, ParseData.DIR_NAME));
       FileInputFormat.addInputPath(job, new Path(segment, ParseText.DIR_NAME));
+
+      if (addBinaryContent) {
+        FileInputFormat.addInputPath(job, new Path(segment, Content.DIR_NAME));
+      }
     }
 
     FileInputFormat.addInputPath(job, new Path(crawlDb, CrawlDb.CURRENT_NAME));
Index: src/java/org/apache/nutch/indexer/IndexingJob.java
===================================================================
--- src/java/org/apache/nutch/indexer/IndexingJob.java	(revision 1693468)
+++ src/java/org/apache/nutch/indexer/IndexingJob.java	(working copy)
@@ -83,7 +83,23 @@
   public void index(Path crawlDb, Path linkDb, List<Path> segments,
       boolean noCommit, boolean deleteGone, String params, boolean filter,
       boolean normalize) throws IOException {
+    index(crawlDb, linkDb, segments, noCommit, deleteGone, params, false,
+        false, false);
+  }
 
+  public void index(Path crawlDb, Path linkDb, List<Path> segments,
+      boolean noCommit, boolean deleteGone, String params,
+      boolean filter, boolean normalize, boolean addBinaryContent) throws IOException {
+    index(crawlDb, linkDb, segments, noCommit, deleteGone, params, false,
+        false, false, false);
+  }
+
+  public void index(Path crawlDb, Path linkDb, List<Path> segments,
+      boolean noCommit, boolean deleteGone, String params,
+      boolean filter, boolean normalize, boolean addBinaryContent,
+      boolean base64) throws IOException {
+
+
     SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
     long start = System.currentTimeMillis();
     LOG.info("Indexer: starting at " + sdf.format(start));
@@ -94,11 +110,17 @@
     LOG.info("Indexer: deleting gone documents: " + deleteGone);
     LOG.info("Indexer: URL filtering: " + filter);
     LOG.info("Indexer: URL normalizing: " + normalize);
-
+    if (addBinaryContent) {
+      if (base64) {
+        LOG.info("Indexer: adding binary content as Base64");
+      } else {
+        LOG.info("Indexer: adding binary content");
+      }
+    }        
     IndexWriters writers = new IndexWriters(getConf());
     LOG.info(writers.describe());
 
-    IndexerMapReduce.initMRJob(crawlDb, linkDb, segments, job);
+    IndexerMapReduce.initMRJob(crawlDb, linkDb, segments, job, addBinaryContent);
 
     // NOW PASSED ON THE COMMAND LINE AS A HADOOP PARAM
     // job.set(SolrConstants.SERVER_URL, solrUrl);
@@ -106,6 +128,7 @@
     job.setBoolean(IndexerMapReduce.INDEXER_DELETE, deleteGone);
     job.setBoolean(IndexerMapReduce.URL_FILTERING, filter);
     job.setBoolean(IndexerMapReduce.URL_NORMALIZING, normalize);
+    job.setBoolean(IndexerMapReduce.INDEXER_BINARY_AS_BASE64, base64);
 
     if (params != null) {
       job.set(IndexerMapReduce.INDEXER_PARAMS, params);
@@ -141,7 +164,8 @@
   public int run(String[] args) throws Exception {
     if (args.length < 2) {
       System.err
-      .println("Usage: Indexer <crawldb> [-linkdb <linkdb>] [-params k1=v1&k2=v2...] (<segment> ... | -dir <segments>) [-noCommit] [-deleteGone] [-filter] [-normalize]");
+      //.println("Usage: Indexer <crawldb> [-linkdb <linkdb>] [-params k1=v1&k2=v2...] (<segment> ... | -dir <segments>) [-noCommit] [-deleteGone] [-filter] [-normalize]");
+      .println("Usage: Indexer <crawldb> [-linkdb <linkdb>] [-params k1=v1&k2=v2...] (<segment> ... | -dir <segments>) [-noCommit] [-deleteGone] [-filter] [-normalize] [-addBinaryContent] [-base64]");
       IndexWriters writers = new IndexWriters(getConf());
       System.err.println(writers.describe());
       return -1;
@@ -157,6 +181,8 @@
     boolean deleteGone = false;
     boolean filter = false;
     boolean normalize = false;
+    boolean addBinaryContent = false;
+    boolean base64 = false;
 
     for (int i = 1; i < args.length; i++) {
       if (args[i].equals("-linkdb")) {
@@ -180,6 +206,10 @@
         filter = true;
       } else if (args[i].equals("-normalize")) {
         normalize = true;
+      } else if (args[i].equals("-addBinaryContent")) {
+        addBinaryContent = true;
+      } else if (args[i].equals("-base64")) {
+        base64 = true;
       } else if (args[i].equals("-params")) {
         params = args[++i];
       } else {
@@ -188,8 +218,7 @@
     }
 
     try {
-      index(crawlDb, linkDb, segments, noCommit, deleteGone, params, filter,
-          normalize);
+      index(crawlDb, linkDb, segments, noCommit, deleteGone, params, filter, normalize, addBinaryContent, base64);
       return 0;
     } catch (final Exception e) {
       LOG.error("Indexer: " + StringUtils.stringifyException(e));
Index: src/java/org/apache/nutch/indexer/NutchDocument.java
===================================================================
--- src/java/org/apache/nutch/indexer/NutchDocument.java	(revision 1693468)
+++ src/java/org/apache/nutch/indexer/NutchDocument.java	(working copy)
@@ -30,6 +30,7 @@
 import org.apache.hadoop.io.Writable;
 import org.apache.hadoop.io.WritableUtils;
 import org.apache.nutch.metadata.Metadata;
+import org.json.simple.JSONObject;
 
 /** A {@link NutchDocument} is the unit of indexing. */
 public class NutchDocument implements Writable,
@@ -141,4 +142,17 @@
     sb.append("}\n");
     return sb.toString();
   }
+  
+  public String toJSON() {
+    JSONObject json = new JSONObject();
+    json.put("url", fields.get("url").getValues().get(0).toString().replaceAll("\\\\", ""));
+    json.put("timestamp", JSONObject.escape(fields.get("timestamp").getValues().get(0).toString()));
+    json.put("team", JSONObject.escape(fields.get("team").getValues().get(0).toString()));
+    json.put("crawler", JSONObject.escape(fields.get("crawler").getValues().get(0).toString()));
+    json.put("content_type", JSONObject.escape(fields.get("content_type").getValues().get(0).toString()));
+    json.put("raw_content", JSONObject.escape(fields.get("raw_content").getValues().get(0).toString()));
+//    json.put("crawl_data", JSONValue.toJSONString(fields.get("crawl_data").getValues().get(0)));    
+
+    return json.toJSONString();
+  }
 }
Index: src/plugin/build.xml
===================================================================
--- src/plugin/build.xml	(revision 1693468)
+++ src/plugin/build.xml	(working copy)
@@ -33,6 +33,7 @@
      <ant dir="index-anchor" target="deploy"/>
      <ant dir="index-geoip" target="deploy"/>
      <ant dir="index-more" target="deploy"/>
+     <ant dir="index-memex-atf" target="deploy"/>
      <ant dir="index-replace" target="deploy"/>
      <ant dir="index-static" target="deploy"/>
      <ant dir="index-metadata" target="deploy"/>
@@ -40,6 +41,7 @@
      <ant dir="indexer-dummy" target="deploy"/>
      <ant dir="indexer-elastic" target="deploy"/>
      <ant dir="indexer-solr" target="deploy"/>
+     <ant dir="indexer-memex" target="deploy"/>
      <ant dir="language-identifier" target="deploy"/>
      <ant dir="lib-http" target="deploy"/>
      <ant dir="lib-nekohtml" target="deploy"/>
@@ -138,6 +140,7 @@
     <ant dir="index-anchor" target="clean"/>
     <ant dir="index-geoip" target="clean"/>
     <ant dir="index-more" target="clean"/>
+    <ant dir="index-memex-atf" target="clean"/>
     <ant dir="index-static" target="clean"/>
     <ant dir="index-replace" target="clean"/>
     <ant dir="index-metadata" target="clean"/>
@@ -144,6 +147,7 @@
     <ant dir="mimetype-filter" target="clean"/>
     <ant dir="indexer-dummy" target="clean"/>
     <ant dir="indexer-elastic" target="clean"/>
+    <ant dir="indexer-memex" target="clean"/>
     <ant dir="indexer-solr" target="clean"/>
     <ant dir="language-identifier" target="clean"/>
     <!-- <ant dir="lib-commons-httpclient" target="clean"/> -->
Index: src/plugin/index-memex-atf/build.xml
===================================================================
--- src/plugin/index-memex-atf/build.xml	(revision 0)
+++ src/plugin/index-memex-atf/build.xml	(working copy)
@@ -0,0 +1,22 @@
+<?xml version="1.0"?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<project name="index-memex-atf" default="jar-core">
+
+  <import file="../build-plugin.xml"/>
+
+</project>
Index: src/plugin/index-memex-atf/ivy.xml
===================================================================
--- src/plugin/index-memex-atf/ivy.xml	(revision 0)
+++ src/plugin/index-memex-atf/ivy.xml	(working copy)
@@ -0,0 +1,41 @@
+<?xml version="1.0" ?>
+
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+
+<ivy-module version="1.0">
+  <info organisation="org.apache.nutch" module="${ant.project.name}">
+    <license name="Apache 2.0"/>
+    <ivyauthor name="Apache Nutch Team" url="http://nutch.apache.org"/>
+    <description>
+        Apache Nutch
+    </description>
+  </info>
+
+  <configurations>
+    <include file="../../..//ivy/ivy-configurations.xml"/>
+  </configurations>
+
+  <publications>
+    <!--get the artifact from our module name-->
+    <artifact conf="master"/>
+  </publications>
+
+  <dependencies>
+  </dependencies>
+  
+</ivy-module>
Index: src/plugin/index-memex-atf/plugin.xml
===================================================================
--- src/plugin/index-memex-atf/plugin.xml	(revision 0)
+++ src/plugin/index-memex-atf/plugin.xml	(working copy)
@@ -0,0 +1,42 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<plugin
+   id="index-memex-atf"
+   name="Memex ATF ES Indexing Filter"
+   version="1.0.0"
+   provider-name="nutch.org">
+
+
+   <runtime>
+      <library name="index-memex-atf.jar">
+         <export name="*"/>
+      </library>
+   </runtime>
+
+   <requires>
+      <import plugin="nutch-extensionpoints"/>
+   </requires>
+
+   <extension id="org.apache.nutch.index.memex.atf"
+              name="Nutch Memex ATF Indexing Filter"
+              point="org.apache.nutch.indexer.IndexingFilter">
+      <implementation id="MemexATFIndexingFilter"
+         class="org.apache.nutch.index.memex.atf.MemexATFIndexingFilter"/>
+   </extension>
+
+</plugin>
+
Index: src/plugin/index-memex-atf/src/java/org/apache/nutch/index/memex/atf/MemexATFIndexingFilter.java
===================================================================
--- src/plugin/index-memex-atf/src/java/org/apache/nutch/index/memex/atf/MemexATFIndexingFilter.java	(revision 0)
+++ src/plugin/index-memex-atf/src/java/org/apache/nutch/index/memex/atf/MemexATFIndexingFilter.java	(working copy)
@@ -0,0 +1,142 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.nutch.index.memex.atf;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.io.Text;
+import org.apache.nutch.crawl.CrawlDatum;
+import org.apache.nutch.crawl.Inlinks;
+import org.apache.nutch.indexer.IndexingException;
+import org.apache.nutch.indexer.IndexingFilter;
+import org.apache.nutch.indexer.NutchDocument;
+import org.apache.nutch.parse.Parse;
+import org.apache.tika.Tika;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * <p>An {@link org.apache.nutch.indexer.IndexingFilter} which augments
+ * {@link org.apache.nutch.indexer.NutchDocument}'s with the following
+ * additional fields</p>
+ * <pre>
+ * {@code
+ *  {
+ *   url : <url of raw page>,
+ *   timestamp: <timestamp for data when scraped, in epoch milliseconds>,
+ *   team: <name of crawling team>,
+ *   crawler: <name of crawler; each type of crawler should have a distinct name or reference>,
+ *   raw_content: <full text of raw crawled page>,
+ *   content_type: <IANA mimetype representing the crawl_data content>,
+ *   crawl_data {
+ *     content: <optional; used to store cleaned/processed text, etc>,
+ *     images:[an array of URIs to the images present within the document],
+ *     videos:[an array of URIs to the videos present within the document]
+ *   }
+ *  }
+ * }
+ * </pre>
+ * <p>This plugin is specific to the Memex ATF domain task and is use used
+ * specifically to augment documents prior to them being indexed into a master
+ * ElasticSearch cluster.</p>
+ */
+public class MemexATFIndexingFilter implements IndexingFilter {
+
+  public static final Logger LOG = LoggerFactory
+      .getLogger(MemexATFIndexingFilter.class);
+  private Configuration conf;
+
+  private String[] IMAGES = {"video/x-flv", "video/mp4", "application/x-mpegURL", 
+      "video/MP2T", "video/3gpp", "video/quicktime", "video/x-msvideo", "video/x-ms-wmv"};
+
+  private String[] VIDEOS = {"image/gif", "image/jpeg", "image/pjpeg", "image/png", "image/bmp",
+      "image/svg+xml", "image/tiff", "image/vnd.djvu"};
+
+  /**
+   * @see org.apache.hadoop.conf.Configurable#getConf()
+   */
+  @Override
+  public Configuration getConf() {
+    return this.conf;
+  }
+
+  /**
+   * @see org.apache.hadoop.conf.Configurable#setConf(org.apache.hadoop.conf.Configuration)
+   */
+  @Override
+  public void setConf(Configuration conf) {
+    this.conf = conf;
+  }
+
+  /**
+   * 
+   * @param doc
+   *          The {@link org.apache.nutch.indexer.NutchDocument} object
+   * @param parse
+   *          The relevant {@link org.apache.nutch.parse.Parse} object passing through the filter
+   * @param url
+   *          URL key to be filtered for corresponding fields
+   * @param datum
+   *          The {@link org.apache.nutch.crawl.CrawlDatum} entry relative to the URL key
+   * @param inlinks
+   *          The {@link org.apache.nutch.crawl.Inlinks} for the given URL
+   * @return filtered {@link org.apache.nutch.indexer.NutchDocument}
+   * @see org.apache.nutch.indexer.IndexingFilter#filter(org.apache.nutch.indexer.NutchDocument, 
+   * org.apache.nutch.parse.Parse, org.apache.hadoop.io.Text, org.apache.nutch.crawl.CrawlDatum, 
+   * org.apache.nutch.crawl.Inlinks)
+   */
+  @Override
+  public NutchDocument filter(NutchDocument doc, Parse parse, Text url,
+      CrawlDatum datum, Inlinks inlinks) throws IndexingException {
+    Tika tika = new Tika();
+    doc.add("url", url);
+    doc.add("timestamp", datum.getFetchTime());
+    doc.add("team", "NASA_JPL");
+    doc.add("crawler", conf.get("http.agent.version", "Nutch-1.11-SNAPSHOT"));
+    doc.add("content_type", tika.detect(url.toString()));
+    HashMap<String, ArrayList<String>> crawlMap = new HashMap<String, ArrayList<String>>();
+
+    crawlMap.put("content", new ArrayList<String>(Arrays.asList(parse.getText())));
+
+    if (inlinks != null) {
+      List<String> linksList = Arrays.asList(inlinks.getAnchors());
+      ArrayList<String> images = new ArrayList<String>();
+      ArrayList<String> videos = new ArrayList<String>();
+
+      for (int i = 0; i < linksList.size(); i++) {
+        String mimeType = null;
+        mimeType = tika.detect(linksList.get(i));
+        if (Arrays.asList(IMAGES).contains(mimeType)) {
+          images.add(linksList.get(i));
+        } else if (Arrays.asList(VIDEOS).contains(mimeType)) {
+          videos.add(linksList.get(i));
+        }
+      }
+      crawlMap.put("images", images);
+      crawlMap.put("videos", videos);
+    }
+
+
+    doc.add("crawl_data", crawlMap);
+    return doc;
+  }
+
+}
Index: src/plugin/index-memex-atf/src/java/org/apache/nutch/index/memex/atf/package-info.java
===================================================================
--- src/plugin/index-memex-atf/src/java/org/apache/nutch/index/memex/atf/package-info.java	(revision 0)
+++ src/plugin/index-memex-atf/src/java/org/apache/nutch/index/memex/atf/package-info.java	(working copy)
@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/**
+ * <p>An {@link org.apache.nutch.indexer.IndexingFilter} which augments
+ * {@link org.apache.nutch.indexer.NutchDocument}'s with the following
+ * additional fields</p>
+ * <pre>
+ * {@code
+ *  {
+ *   url : <url of raw page>,
+ *   timestamp: <timestamp for data when scraped, in epoch milliseconds>,
+ *   team: <name of crawling team>,
+ *   crawler: <name of crawler; each type of crawler should have a distinct name or reference>,
+ *   raw_content: <full text of raw crawled page>,
+ *   content_type: <IANA mimetype representing the crawl_data content>,
+ *   crawl_data {
+ *     content: <optional; used to store cleaned/processed text, etc>,
+ *     images:[an array of URIs to the images present within the document],
+ *     videos:[an array of URIs to the videos present within the document]
+ *   }
+ * }
+ * </pre>
+ * <p>This plugin is specific to the Memex ATF domain task and is use used
+ * specifically to augment documents prior to them being indexed into a master
+ * ElasticSearch cluster.</p>
+ */
+package org.apache.nutch.index.memex.atf;
\ No newline at end of file
Index: src/plugin/indexer-memex/build-ivy.xml
===================================================================
--- src/plugin/indexer-memex/build-ivy.xml	(revision 0)
+++ src/plugin/indexer-memex/build-ivy.xml	(working copy)
@@ -0,0 +1,54 @@
+<?xml version="1.0"?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<project name="indexer-memex" default="deps-jar" xmlns:ivy="antlib:org.apache.ivy.ant">
+
+    <property name="ivy.install.version" value="2.1.0" />
+    <condition property="ivy.home" value="${env.IVY_HOME}">
+      <isset property="env.IVY_HOME" />
+    </condition>
+    <property name="ivy.home" value="${user.home}/.ant" />
+    <property name="ivy.checksums" value="" />
+    <property name="ivy.jar.dir" value="${ivy.home}/lib" />
+    <property name="ivy.jar.file" value="${ivy.jar.dir}/ivy.jar" />
+
+    <target name="download-ivy" unless="offline">
+
+        <mkdir dir="${ivy.jar.dir}"/>
+        <!-- download Ivy from web site so that it can be used even without any special installation -->
+        <get src="http://repo2.maven.org/maven2/org/apache/ivy/ivy/${ivy.install.version}/ivy-${ivy.install.version}.jar" 
+             dest="${ivy.jar.file}" usetimestamp="true"/>
+    </target>
+
+    <target name="init-ivy" depends="download-ivy">
+      <!-- try to load ivy here from ivy home, in case the user has not already dropped
+              it into ant's lib dir (note that the latter copy will always take precedence).
+              We will not fail as long as local lib dir exists (it may be empty) and
+              ivy is in at least one of ant's lib dir or the local lib dir. -->
+        <path id="ivy.lib.path">
+            <fileset dir="${ivy.jar.dir}" includes="*.jar"/>
+
+        </path>
+        <taskdef resource="org/apache/ivy/ant/antlib.xml"
+                 uri="antlib:org.apache.ivy.ant" classpathref="ivy.lib.path"/>
+    </target>
+
+  <target name="deps-jar" depends="init-ivy">
+    <ivy:retrieve pattern="lib/[artifact]-[revision].[ext]"/>
+  </target>
+
+</project>
Index: src/plugin/indexer-memex/build.xml
===================================================================
--- src/plugin/indexer-memex/build.xml	(revision 0)
+++ src/plugin/indexer-memex/build.xml	(working copy)
@@ -0,0 +1,22 @@
+<?xml version="1.0"?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<project name="indexer-memex" default="jar-core">
+
+  <import file="../build-plugin.xml" />
+
+</project>
Index: src/plugin/indexer-memex/howto_upgrade.txt
===================================================================
--- src/plugin/indexer-memex/howto_upgrade.txt	(revision 0)
+++ src/plugin/indexer-memex/howto_upgrade.txt	(working copy)
@@ -0,0 +1,6 @@
+1. Upgrade indexer-memex dependencies in src/plugin/indexer-memex/ivy.xml
+
+2. Upgrade the jest specific dependencies in src/plugin/indexer-memex/plugin.xml
+   To get the list of dependencies and their versions execute:
+   $ ant -f ./build-ivy.xml
+   $ ls lib/
Index: src/plugin/indexer-memex/ivy.xml
===================================================================
--- src/plugin/indexer-memex/ivy.xml	(revision 0)
+++ src/plugin/indexer-memex/ivy.xml	(working copy)
@@ -0,0 +1,43 @@
+<?xml version="1.0" ?>
+
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+
+<ivy-module version="1.0">
+  <info organisation="org.apache.nutch" module="${ant.project.name}">
+    <license name="Apache 2.0"/>
+    <ivyauthor name="Apache Nutch Team" url="http://nutch.apache.org"/>
+    <description>
+        Apache Nutch
+    </description>
+  </info>
+
+  <configurations>
+    <include file="../../..//ivy/ivy-configurations.xml"/>
+  </configurations>
+
+  <publications>
+    <!--get the artifact from our module name-->
+    <artifact conf="master"/>
+  </publications>
+
+  <dependencies>
+    <dependency org="io.searchbox" name="jest" rev="0.1.6"
+        conf="*->default"/>
+  </dependencies>
+  
+</ivy-module>
Index: src/plugin/indexer-memex/plugin.xml
===================================================================
--- src/plugin/indexer-memex/plugin.xml	(revision 0)
+++ src/plugin/indexer-memex/plugin.xml	(working copy)
@@ -0,0 +1,51 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+  
+  http://www.apache.org/licenses/LICENSE-2.0
+  
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<plugin id="indexer-memex" name="ElasticIndexWriter" version="1.0.0"
+  provider-name="nutch.apache.org">
+
+  <runtime>
+    <library name="indexer-memex.jar">
+      <export name="*" />
+    </library>
+    
+    <library name="commons-codec-1.9.jar"/>
+    <library name="commons-lang3-3.4.jar"/>
+    <library name="commons-logging-1.2.jar"/>
+    <library name="gson-2.3.1.jar"/>
+    <library name="guava-18.0.jar"/>
+    <library name="httpasyncclient-4.1.jar"/>
+    <library name="httpclient-4.4.1.jar"/>
+    <library name="httpcore-4.4.1.jar"/>
+    <library name="httpcore-nio-4.4.1.jar"/>
+    <library name="jest-0.1.6.jar"/>
+    <library name="jest-common-0.1.6.jar"/>
+    <library name="slf4j-api-1.7.12.jar"/>
+  </runtime>
+
+  <requires>
+    <import plugin="nutch-extensionpoints" />
+  </requires>
+
+  <extension id="org.apache.nutch.indexer.memex"
+    name="Memex Index Writer"
+    point="org.apache.nutch.indexer.IndexWriter">
+    <implementation id="MemexIndexWriter"
+      class="org.apache.nutch.indexwriter.memex.MemexIndexWriter" />
+  </extension>
+
+</plugin>
Index: src/plugin/indexer-memex/src/java/org/apache/nutch/indexwriter/memex/MemexIndexWriter.java
===================================================================
--- src/plugin/indexer-memex/src/java/org/apache/nutch/indexwriter/memex/MemexIndexWriter.java	(revision 0)
+++ src/plugin/indexer-memex/src/java/org/apache/nutch/indexwriter/memex/MemexIndexWriter.java	(working copy)
@@ -0,0 +1,174 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.nutch.indexwriter.memex;
+
+import io.searchbox.client.JestClient;
+import io.searchbox.client.JestClientFactory;
+import io.searchbox.client.JestResult;
+import io.searchbox.client.config.HttpClientConfig;
+import io.searchbox.core.Bulk;
+import io.searchbox.core.Index;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.mapred.JobConf;
+import org.apache.nutch.indexer.IndexWriter;
+import org.apache.nutch.indexer.NutchDocument;
+import org.apache.solr.common.SolrInputDocument;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * <p>An {@link org.apache.nutch.indexer.IndexingWriter} which writes
+ * {@link org.apache.nutch.indexer.NutchDocument}'s into an ElasticSearch
+ * index in the following schema. This schema is defined within the 
+ * {@link org.apache.nutch.index.memex.atf.MemexATFIndexingFilter}</p>
+ * <pre>
+ * {@code
+ *  {
+ *   url : <url of raw page>,
+ *   timestamp: <timestamp for data when scraped, in epoch milliseconds>,
+ *   team: <name of crawling team>,
+ *   crawler: <name of crawler; each type of crawler should have a distinct name or reference>,
+ *   raw_content: <full text of raw crawled page>,
+ *   content_type: <IANA mimetype representing the crawl_data content>,
+ *   crawl_data {
+ *     content: <optional; used to store cleaned/processed text, etc>,
+ *     images:[an array of URIs to the images present within the document],
+ *     videos:[an array of URIs to the videos present within the document]
+ *   }
+ * }
+ * </pre>
+ * <p>This plugin is specific to the Memex ATF domain task and is use used
+ * specifically to augment documents prior to them being indexed into a master
+ * ElasticSearch cluster.</p>
+ */
+public class MemexIndexWriter implements IndexWriter {
+
+  private JestClientFactory factory;
+
+  private JestClient client;
+
+  private Configuration config;
+
+  private static Logger LOG = LoggerFactory.getLogger(MemexIndexWriter.class);
+
+  private final List<NutchDocument> inputDocs = new ArrayList<NutchDocument>();
+  
+  private int batchSize = 50;
+
+
+  /**
+   * @see org.apache.hadoop.conf.Configurable#getConf()
+   */
+  @Override
+  public Configuration getConf() {
+    return config;
+  }
+
+  /**
+   * @see org.apache.hadoop.conf.Configurable#setConf(org.apache.hadoop.conf.Configuration)
+   */
+  @Override
+  public void setConf(Configuration conf) {
+    config = conf;
+  }
+
+
+  /**
+   * @see org.apache.nutch.indexer.IndexWriter#open(org.apache.hadoop.mapred.JobConf, java.lang.String)
+   */
+  @Override
+  public void open(JobConf job, String name) throws IOException {
+    factory = new JestClientFactory();
+    factory.setHttpClientConfig(new HttpClientConfig.
+        Builder("https://els.istresearch.com:9200").multiThreaded(true)
+        .defaultCredentials("memex", "j9fd0LK8.a6olH24U7X81").connTimeout(300000).build());
+    client = factory.getObject();
+  }
+
+  /**
+   * @see org.apache.nutch.indexer.IndexWriter#write(org.apache.nutch.indexer.NutchDocument)
+   */
+  @Override
+  public void write(NutchDocument doc) throws IOException {
+
+    Bulk bulk = new Bulk.Builder()
+    .defaultIndex("memex-domains")
+    .defaultType("autonomy")
+    .addAction(Arrays.asList(
+        new Index.Builder(doc.toJSON()).build()))
+        .build();
+    inputDocs.add(doc);
+    if (inputDocs.size() > batchSize) {
+      JestResult result = client.execute(bulk);
+      LOG.info(result.getJsonString());
+      LOG.info(result.getErrorMessage());
+      LOG.info(result.getPathToResult());
+    }
+
+  }
+
+  /* (non-Javadoc)
+   * @see org.apache.nutch.indexer.IndexWriter#delete(java.lang.String)
+   */
+  @Override
+  public void delete(String key) throws IOException {
+    // TODO Auto-generated method stub
+
+  }
+
+  /**
+   * @see org.apache.nutch.indexer.IndexWriter#update(org.apache.nutch.indexer.NutchDocument)
+   */
+  @Override
+  public void update(NutchDocument doc) throws IOException {
+    write(doc);;
+
+  }
+
+  /* (non-Javadoc)
+   * @see org.apache.nutch.indexer.IndexWriter#commit()
+   */
+  @Override
+  public void commit() throws IOException {
+    // TODO Auto-generated method stub
+
+  }
+
+  /* (non-Javadoc)
+   * @see org.apache.nutch.indexer.IndexWriter#close()
+   */
+  @Override
+  public void close() throws IOException {
+
+  }
+
+  /* (non-Javadoc)
+   * @see org.apache.nutch.indexer.IndexWriter#describe()
+   */
+  @Override
+  public String describe() {
+    // TODO Auto-generated method stub
+    return null;
+  }
+
+}
Index: src/plugin/indexer-memex/src/java/org/apache/nutch/indexwriter/memex/package-info.java
===================================================================
--- src/plugin/indexer-memex/src/java/org/apache/nutch/indexwriter/memex/package-info.java	(revision 0)
+++ src/plugin/indexer-memex/src/java/org/apache/nutch/indexwriter/memex/package-info.java	(working copy)
@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/**
+ * <p>An {@link org.apache.nutch.indexer.IndexingWriter} which writes
+ * {@link org.apache.nutch.indexer.NutchDocument}'s into an ElasticSearch
+ * index in the following schema. This schema is defined within the 
+ * {@link org.apache.nutch.index.memex.atf.MemexATFIndexingFilter}</p>
+ * <pre>
+ * {@code
+ *  {
+ *   url : <url of raw page>,
+ *   timestamp: <timestamp for data when scraped, in epoch milliseconds>,
+ *   team: <name of crawling team>,
+ *   crawler: <name of crawler; each type of crawler should have a distinct name or reference>,
+ *   raw_content: <full text of raw crawled page>,
+ *   content_type: <IANA mimetype representing the crawl_data content>,
+ *   crawl_data {
+ *     content: <optional; used to store cleaned/processed text, etc>,
+ *     images:[an array of URIs to the images present within the document],
+ *     videos:[an array of URIs to the videos present within the document]
+ *   }
+ * }
+ * </pre>
+ * <p>This plugin is specific to the Memex ATF domain task and is use used
+ * specifically to augment documents prior to them being indexed into a master
+ * ElasticSearch cluster.</p>
+ */
+package org.apache.nutch.indexwriter.memex;
\ No newline at end of file
